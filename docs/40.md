# 用于物体检测的深度学习的最新进展(1)

> 原文：<https://www.dlology.com/blog/recent-advances-in-deep-learning-for-object-detection/>

###### 发帖人:[程维](/blog/author/Chengwei/)三年零四个月前

([评论](/blog/recent-advances-in-deep-learning-for-object-detection/#disqus_thread))

![advance](img/dfe0945e491f3739e2501380337817b8.png)

在训练自定义对象检测模型时， [TensorFlow 对象检测 API](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) 和 [MMdetection](https://www.dlology.com/blog/how-to-train-an-object-detection-model-with-mmdetection/) (PyTorch)是两个现成的选项，我已经向您展示了如何在 Google Colab 的免费 GPU 资源上完成这项工作。

这两个框架易于使用，配置接口简单，让框架源代码来完成繁重的工作。但是你有没有想过这些年来深度学习对象检测算法是如何进化的，它们的优缺点是什么？

我发现这篇论文- [物体检测深度学习的最新进展](https://arxiv.org/pdf/1908.03673.pdf)很好地回答了这个问题。让我总结一下我所学到的，希望能以更直观的方式阐述。

*文字颜色: **pro** / **cons***

## 检测范例

### 两级检测器

![two-stage](img/c3835d3c31ab4b16b5cea7878125bdfa.png)

 <svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ev="http://www.w3.org/2001/xml-events" xmlns:v="http://schemas.microsoft.com/visio/2003/SVGExtensions/" viewBox="0 0 592.766 619.695" xml:space="preserve" color-interpolation-filters="sRGB" style="fill: none; fill-rule: evenodd; font-size: 12px; overflow: visible; stroke-linecap: square; stroke-miterlimit: 3;"><g v:mid="0" v:index="1" v:groupcontext="foregroundPage"><title>页-1</title> <g id="shape13-1" v:mid="13" v:groupcontext="shape" transform="translate(18.375,-525.013)"><title>工作表.13</title> <desc>R-CNN</desc> <text x="42.68" y="585.74" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">R-CNN</text></g> <g id="shape14-4" v:mid="14" v:groupcontext="shape" transform="translate(18.375,-392.548)"><title>工作表.14</title> <desc>SPP-net Spatial Pyramid Pooling</desc> <text x="39.3" y="540.86" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">SPP-netSpatial Pyramid <tspan x="38.63" dy="1.2em" style="font-size: 1em;">Pooling</tspan></text></g> <g id="shape15-9" v:mid="15" v:groupcontext="shape" transform="translate(18.375,-286.276)"><title>工作表.15</title> <desc>Fast RCNN</desc> <text x="31.59" y="570.76" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Fast RCNN</text></g> <g id="shape16-12" v:mid="16" v:groupcontext="shape" transform="translate(138,-286.276)"><title>工作表.16</title> <desc>ROI pooling layer. The feature extraction, region classificat...</desc> <text x="4" y="536.93" style="fill: #00882b; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">ROI pooling layer. The feature extraction, region classification and <tspan x="4" dy="1.2em" style="font-size: 1em;">bounding box regression steps can all be optimized end</tspan>-to-end, without <tspan x="4" dy="1.2em" style="font-size: 1em;">extra cache space to store features.</tspan><tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">The proposal generation step still relied on traditional methods such as</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">Selective Search or Edge Boxes.</tspan></text></g> <g id="shape17-19" v:mid="17" v:groupcontext="shape" transform="translate(138,-525.013)"><title>工作表.17</title> <desc>The whole detection framework could not be optimized in an en...</desc> <text x="4" y="577.34" style="fill: #ff0000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">The whole detection framework could not be optimized in an end-to-end <tspan x="4" dy="1.2em" style="font-size: 1em;">manner, making it difficult to obtain global optimal solution.</tspan></text></g> <g id="shape18-23" v:mid="18" v:groupcontext="shape" transform="translate(138,-392.548)"><title>工作表.18</title> <desc>Spatial Pyramid Pooling (SPP) layer achieved better results a...</desc> <text x="4" y="507.26" style="fill: #00882b; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Spatial Pyramid Pooling (SPP) layer achieved better results and had a <tspan x="4" dy="1.2em" style="font-size: 1em;">significantly faster inference speed.</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">However the training of SPP</tspan><tspan style="fill: #ff0000; font-size: 1em;">-</tspan><tspan style="fill: #ff0000; font-size: 1em;">net was still multi</tspan><tspan style="fill: #ff0000; font-size: 1em;">-</tspan><tspan style="fill: #ff0000; font-size: 1em;">stage and thus it could not</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">be optimized end</tspan><tspan style="fill: #ff0000; font-size: 1em;">-</tspan><tspan style="fill: #ff0000; font-size: 1em;">to</tspan><tspan style="fill: #ff0000; font-size: 1em;">-</tspan><tspan style="fill: #ff0000; font-size: 1em;">end.</tspan><tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">SPP layer did not back</tspan><tspan style="fill: #ff0000; font-size: 1em;">-</tspan><tspan style="fill: #ff0000; font-size: 1em;">propagate gradients to convolutional kernels and</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">thus all the parameters before the SPP layer were frozen, limited learning</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">capability of deep backbone architectures.</tspan></text></g> <g id="shape19-42" v:mid="19" v:groupcontext="shape" transform="translate(18.375,-136.227)"><title>工作表.19</title> <desc>Faster R-CNN</desc> <text x="21.94" y="548.76" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Faster R-CNN</text></g> <g id="shape20-45" v:mid="20" v:groupcontext="shape" transform="translate(138,-136.227)"><title>工作表.20</title> <desc>Region Proposal Network(RPN) The whole framework could be opt...</desc> <text x="4" y="489.96" style="fill: #459b5c; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Region Proposal Network(RPN)<tspan x="4" dy="1.2em" style="font-size: 1em;">The whole framework could be optimized in an end</tspan>-to-end manner on <tspan x="4" dy="1.2em" style="font-size: 1em;">training data.</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">The computation was not shared in the region classification step, where</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">each feature vector still needed to go through a sequence of FC layers</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">separately.</tspan><tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">used a single deep layer feature map to make the final prediction. This</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">made it difficult to detect objects at different scales.</tspan></text></g> <g id="shape21-55" v:mid="21" v:groupcontext="shape" transform="translate(18.375,-72.4479)"><title>工作表.21</title> <desc>Region-based Fully Convolutional Networks (R-FCN)</desc> <text x="6.33" y="574.87" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Region-based Fully <tspan x="20.29" dy="1.2em" style="font-size: 1em;">Convolutional</tspan> <tspan x="9.17" dy="1.2em" style="font-size: 1em;">Networks (R</tspan>-FCN)</text></g> <g id="shape22-60" v:mid="22" v:groupcontext="shape" transform="translate(138,-72.4479)"><title>工作表.22</title> <desc>The detector achieved competitive results compared to Faster ...</desc> <text x="4" y="574.87" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">The detector achieved competitive results compared to Faster RCNN <tspan x="4" dy="1.2em" style="font-size: 1em;">without region</tspan>-wise fully connected layer operations.<tspan x="4" dy="1.2em" style="font-size: 1em;">Position-Sensitive Score Map.</tspan></text></g> <g id="shape23-65" v:mid="23" v:groupcontext="shape" transform="translate(18.375,-18.375)"><title>工作表.23</title> <desc>Feature Pyramid Networks(FPN)</desc> <text x="12.78" y="588.46" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Feature Pyramid <tspan x="16.81" dy="1.2em" style="font-size: 1em;">Networks(FPN)</tspan></text></g> <g id="shape24-69" v:mid="24" v:groupcontext="shape" transform="translate(138,-18.375)"><title>工作表.24</title> <desc>Enable object detection in feature maps at different scales.</desc> <text x="51.91" y="596.86" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Enable object detection in feature maps at different scales.</text></g></g></svg>

### 一级检测器

![one-stage](img/3ecb05c81e03a75033fba25ddae9a98f.png)

 <svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ev="http://www.w3.org/2001/xml-events" xmlns:v="http://schemas.microsoft.com/visio/2003/SVGExtensions/" viewBox="0 0 512.97 589.506" xml:space="preserve" color-interpolation-filters="sRGB" style="fill: none; fill-rule: evenodd; font-size: 12px; overflow: visible; stroke-linecap: square; stroke-miterlimit: 3;"><g v:mid="113" v:index="38" v:groupcontext="foregroundPage"><title>adv2</title> <g id="shape1-1" v:mid="1" v:groupcontext="shape" transform="translate(18.375,-471.385)"><title>工作表.1</title> <desc>OverFeat</desc> <text x="36.75" y="543.53" style="fill: #000000; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">OverFeat</text></g> <g id="shape2-4" v:mid="2" v:groupcontext="shape" transform="translate(137.43,-471.384)"><title>工作表.2</title> <desc>In order to detect multiscale objects, the input image was re...</desc> <text x="6.94" y="512.33" style="fill: #198742; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">In order to detect multiscale objects, the input image was resized <tspan x="4" dy="1.2em" style="font-size: 1em;">into multiple scales which were fed into the network. Finally, the</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">predictions across all the scales were merged together.</tspan><tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">However, the training of classifiers and regressors were separated</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">without being jointly optimized.</tspan></text></g> <g id="shape3-11" v:mid="3" v:groupcontext="shape" transform="translate(18.375,-347.256)"><title>工作表.3</title> <desc>YOLO</desc> <text x="45.02" y="531.34" style="fill: #000000; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">YOLO</text></g> <g id="shape4-14" v:mid="4" v:groupcontext="shape" transform="translate(137.43,-347.256)"><title>工作表.4</title> <desc>Divided the whole image into fixed number of grid cells. YOLO...</desc> <text x="4" y="492.34" style="fill: #459b5c; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">Divided the whole image into a fixed number of grid cells.<tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">YOLO faced some challenges: i) it could detect up to only two</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">objects at a given location, which made it difficult to detect small</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">objects and crowded objects. ii) only the last feature map was</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">used for prediction, which was not suitable for predicting objects</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">at multiple scales and aspect ratios</tspan></text></g> <g id="shape5-22" v:mid="5" v:groupcontext="shape" transform="translate(18.375,-250.068)"><title>工作表.5</title> <desc>Single-Shot Mulibox Detector (SSD)</desc> <text x="6.77" y="537.01" style="fill: #000000; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">Single-Shot Mulibox <tspan x="20.88" dy="1.2em" style="font-size: 1em;">Detector (SSD)</tspan></text></g> <g id="shape6-26" v:mid="6" v:groupcontext="shape" transform="translate(137.43,-250.068)"><title>工作表.6</title> <desc>A set of anchors with multiple scales and aspect-ratios were ...</desc> <text x="4" y="505.81" style="fill: #00882b; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">A set of <tspan style="font-size: 1em; font-weight: bold;">anchors</tspan> with multiple scales and aspect-ratios were <tspan x="4" dy="1.2em" style="font-size: 1em;">generated to discretize the output space of bounding boxes,</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">predicted objects on multiple feature maps. (</tspan><tspan style="font-size: 1em; font-weight: bold;">multiple scales</tspan>), <tspan x="4" dy="1.2em" style="font-size: 1em;">hard negative mining.</tspan><tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">The class imbalance between foreground and background is a</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">severe problem in one</tspan><tspan style="fill: #ff0000; font-size: 1em;">-</tspan><tspan style="fill: #ff0000; font-size: 1em;">stage detector.</tspan></text></g> <g id="shape7-38" v:mid="7" v:groupcontext="shape" transform="translate(18.375,-153.306)"><title>工作表.7</title> <desc>RetinaNet</desc> <text x="32.96" y="545.03" style="fill: #000000; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">RetinaNet</text></g> <g id="shape8-41" v:mid="8" v:groupcontext="shape" transform="translate(137.43,-153.306)"><title>工作表.8</title> <desc>Focal loss which suppressed the gradients of easy negative sa...</desc> <text x="4" y="513.83" style="fill: #00882b; font-family: Calibri; font-size: 1.08334em; font-weight: bold;" v:langid="1033">Focal loss<tspan style="font-size: 1em; font-weight: normal;">which suppressed the gradients of easy negative</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">samples instead of simply discarding them.used</tspan> feature pyramid <tspan x="4" dy="1.2em" style="font-size: 1em;">networks</tspan><tspan style="font-size: 1em; font-weight: normal;">to detect multi</tspan><tspan style="font-size: 1em; font-weight: normal;">-</tspan><tspan style="font-size: 1em; font-weight: normal;">scale objects at different levels of</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">feature maps.</tspan></text></g> <g id="shape9-53" v:mid="9" v:groupcontext="shape" transform="translate(18.375,-80.6895)"><title>工作表.9</title> <desc>YOLOv2</desc> <text x="38.79" y="557.31" style="fill: #000000; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">YOLOv2</text></g> <g id="shape10-56" v:mid="10" v:groupcontext="shape" transform="translate(137.43,-80.6895)"><title>工作表.10</title> <desc>Adopted a more powerful deep convolutional backbone. YOLOv2 d...</desc> <text x="4" y="533.91" style="fill: #00882b; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">Adopted a more powerful deep convolutional backbone. YOLOv2 <tspan x="4" dy="1.2em" style="font-size: 1em;">defined better anchor priors by k</tspan>-means clustering from the <tspan x="4" dy="1.2em" style="font-size: 1em;">training data (instead of setting manually). multi</tspan>-scale training <tspan x="4" dy="1.2em" style="font-size: 1em;">techniques.</tspan></text></g> <g id="shape11-62" v:mid="11" v:groupcontext="shape" transform="translate(137.43,-18.375)"><title>工作表.11</title> <desc>Anchor-free object, the goal was to predict keypoints of the ...</desc> <text x="4" y="554.45" style="fill: #00882b; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">Anchor-free object, the goal was to predict key points of the <tspan x="4" dy="1.2em" style="font-size: 1em;">bounding box, instead of trying to fit an object to an anchor.</tspan></text></g> <g id="shape12-66" v:mid="12" v:groupcontext="shape" transform="translate(18.375,-18.375)"><title>工作表.12</title> <desc>CornerNet</desc> <text x="33.31" y="562.25" style="fill: #000000; font-family: Calibri; font-size: 1.08334em;" v:langid="1033">CornerNet</text></g></g></svg>

### 主干架构

##  <svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ev="http://www.w3.org/2001/xml-events" xmlns:v="http://schemas.microsoft.com/visio/2003/SVGExtensions/" viewBox="0 0 496.49 592.474" xml:space="preserve" color-interpolation-filters="sRGB" style="fill: none; fill-rule: evenodd; font-size: 12px; overflow: visible; stroke-linecap: square; stroke-miterlimit: 3;"><g v:mid="116" v:index="39" v:groupcontext="foregroundPage"><title>adv3</title> <g id="shape1-1" v:mid="1" v:groupcontext="shape" transform="translate(18.375,-509.77)"><title>工作表.1</title> <desc>ResNet</desc> <text x="25.14" y="579.99" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">ResNet</text></g> <g id="shape2-4" v:mid="2" v:groupcontext="shape" transform="translate(18.375,-453.377)"><title>工作表.2</title> <desc>ResNet-v2</desc> <text x="17.55" y="567.88" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">ResNet-v2</text></g> <g id="shape3-7" v:mid="3" v:groupcontext="shape" transform="translate(103.466,-453.377)"><title>工作表.3</title> <desc>Appropriate ordering of the Batch Normalization could further...</desc> <text x="4" y="553.34" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Appropriate ordering of the Batch Normalization could further perform <tspan x="4" dy="1.2em" style="font-size: 1em;">better than original ResNet. possible to successfully train a network with</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">more than 1000 layers.</tspan></text></g> <g id="shape4-12" v:mid="4" v:groupcontext="shape" transform="translate(103.466,-509.77)"><title>工作表.4</title> <desc>Reduced optimization difficulties by introducing shortcut con...</desc> <text x="4" y="572.79" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Reduced optimization difficulties by introducing shortcut connections. <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">Shortcut connection, it did not fully utilize features from previous layers.</tspan></text></g> <g id="shape5-16" v:mid="5" v:groupcontext="shape" transform="translate(18.375,-396.973)"><title>工作表.5</title> <desc>DenseNet</desc> <text x="18.73" y="567.74" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">DenseNet</text></g> <g id="shape6-19" v:mid="6" v:groupcontext="shape" transform="translate(103.466,-396.973)"><title>工作表.6</title> <desc>Retained the shallow layer features, and improved information...</desc> <text x="4" y="553.34" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Retained the shallow layer features, and improved information flow, by <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: bold;">concatenating</tspan> the input with the residual output instead of element-wise <tspan x="4" dy="1.2em" style="font-size: 1em;">addition.</tspan></text></g> <g id="shape7-24" v:mid="7" v:groupcontext="shape" transform="translate(103.466,-318.514)"><title>工作表.7</title> <desc>Integrating the advantages of both ResNet and DenseNet. Divid...</desc> <text x="4" y="535.11" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Integrating the advantages of both ResNet and DenseNet.<tspan x="4" dy="1.2em" style="font-size: 1em;">Divides x channels into two parts, used for dense connection computation</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">and element</tspan>-wise summation, the result was the concatenated output of the <tspan x="4" dy="1.2em" style="font-size: 1em;">two branches.</tspan></text></g> <g id="shape8-30" v:mid="8" v:groupcontext="shape" transform="translate(18.375,-318.514)"><title>工作表.8</title> <desc>Dual Path Network(DPN)</desc> <text x="20.37" y="549.51" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Dual Path <tspan x="7.15" dy="1.2em" style="font-size: 1em;">Network(DPN)</tspan></text></g> <g id="shape23-34" v:mid="23" v:groupcontext="shape" transform="translate(18.3757,-252.904)"><title>工作表.23</title> <desc>ResNeXt</desc> <text x="22.02" y="563.27" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">ResNeXt</text></g> <g id="shape24-37" v:mid="24" v:groupcontext="shape" transform="translate(103.466,-252.904)"><title>工作表.24</title> <desc>Considerably reduced computation and memory cost while mainta...</desc> <text x="4" y="541.67" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Considerably reduced computation and memory cost while maintaining <tspan x="4" dy="1.2em" style="font-size: 1em;">comparable classification accuracy. Adopted</tspan> <tspan style="font-size: 1em; font-weight: bold;">group convolution layers</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">which sparsely connects feature map channels to reduce computation</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">cost.</tspan></text></g> <g id="shape25-44" v:mid="25" v:groupcontext="shape" transform="translate(18.3757,-215.768)"><title>工作表.25</title> <desc>MobileNet</desc> <text x="16.54" y="577.51" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">MobileNet</text></g> <g id="shape26-47" v:mid="26" v:groupcontext="shape" transform="translate(103.466,-215.487)"><title>工作表.26</title> <desc>Significantly reduced computation cost as well as number of p...</desc> <text x="4" y="570.16" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Significantly reduced computation cost as well as the number of parameters <tspan x="4" dy="1.2em" style="font-size: 1em;">without significant loss in classification accuracy.</tspan></text></g> <g id="shape27-51" v:mid="27" v:groupcontext="shape" transform="translate(103.466,-159.646)"><title>工作表.27</title> <desc>Increasing model width to improve the learning capacity, appl...</desc> <text x="4" y="553.61" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Increasing model width to improve the learning capacity, applied different <tspan x="4" dy="1.2em" style="font-size: 1em;">scale convolution kernels (1 × 1; 3 × 3 and 5 × 5) on the same feature map</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">in a given layer.</tspan></text></g> <g id="shape28-56" v:mid="28" v:groupcontext="shape" transform="translate(18.3757,-159.646)"><title>工作表.28</title> <desc>GoogleNet</desc> <text x="16.43" y="568.01" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">GoogleNet</text></g> <g id="shape29-59" v:mid="29" v:groupcontext="shape" transform="translate(18.3764,-103.242)"><title>工作表.29</title> <desc>DetNet</desc> <text x="25.04" y="567.87" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">DetNet</text></g> <g id="shape30-62" v:mid="30" v:groupcontext="shape" transform="translate(103.466,-103.242)"><title>工作表.30</title> <desc>Kept high resolution feature maps for prediction with dilated...</desc> <text x="4" y="560.67" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Kept high-resolution feature maps for prediction with<tspan style="font-size: 1em; font-weight: bold;">dilated convolutions</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">to increase receptive fields. Detected objects on multi</tspan>-scale feature maps.</text></g> <g id="shape31-68" v:mid="31" v:groupcontext="shape" transform="translate(18.3764,-18.375)"><title>工作表.31</title> <desc>Hourglass Network</desc> <text x="18.68" y="546.44" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Hourglass <tspan x="21.45" dy="1.2em" style="font-size: 1em;">Network</tspan></text></g> <g id="shape32-72" v:mid="32" v:groupcontext="shape" transform="translate(103.466,-18.375)"><title>工作表.32</title> <desc>First appeared in human pose recognition task. First downsamp...</desc> <text x="4" y="524.84" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">First appeared in the human pose recognition task.<tspan x="4" dy="1.2em" style="font-size: 1em;">First downsampled the input image via a sequence of convolutional layer</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">or pooling layer, and upsampled the feature map via deconvolutional</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">operation. To avoid information loss in downsampling stage, skip</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">connections were used between downsampling and upsampling features.</tspan></text></g> <g id="shape33-79" v:mid="33" v:groupcontext="shape" transform="translate(18.375,-541.934)"><title>工作表.33</title> <desc>VGG16</desc> <text x="25.54" y="579.99" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">VGG16</text></g> <g id="shape34-82" v:mid="34" v:groupcontext="shape" transform="translate(103.466,-541.934)"><title>工作表.34</title> <desc>Increasing depth led to better performance, but also led to o...</desc> <text x="4" y="572.79" style="fill: #00882b; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Increasing depth led to better performance, <tspan style="fill: #ff0000; font-size: 1em;">but also led to optimization</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">challenges.</tspan></text></g></g></svg> Conclusion and further reading

这篇快速帖子从三个方面总结了深度学习对象检测的最新进展，两阶段检测器、一阶段检测器和主干架构。下次您使用第三方开源框架训练自定义对象检测时，您将更有信心通过检查它们的优缺点来为您的应用程序选择最佳选项。

在下一篇文章中，我将完成我们在论文中留下的内容，即建议生成、特征表示学习和学习策略。如果你感兴趣，强烈建议看一下[论文](https://arxiv.org/pdf/1908.03673.pdf)，它将非常值得你花时间去读。

*   标签:
*   [深度学习](/blog/tag/deep-learning/)，
*   [教程](/blog/tag/tutorial/)

[Share on Twitter](https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/recent-advances-in-deep-learning-for-object-detection/&text=Recent%20Advances%20in%20Deep%20Learning%20for%20Object%20Detection%20-%20Part%201) [Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/recent-advances-in-deep-learning-for-object-detection/)

*   [←如何在 Nvidia Docker 容器中的 Jetson Nano 上运行 Keras 模型](/blog/how-to-run-keras-model-on-jetson-nano-in-nvidia-docker-container/)
*   [用于物体检测的深度学习的最新进展-第二部分→](/blog/recent-advances-in-deep-learning-for-object-detection-part-2/)