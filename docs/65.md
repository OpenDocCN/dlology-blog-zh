# 用于物体检测的深度学习的最新进展——第二部分

> 原文:[https://www . dlology . com/blog/recent-advances-in-deep-learning-for-object-detection-part-2/](https://www.dlology.com/blog/recent-advances-in-deep-learning-for-object-detection-part-2/)

###### 发帖人:[程维](/blog/author/Chengwei/)三年零四个月前

([评论](/blog/recent-advances-in-deep-learning-for-object-detection-part-2/#disqus_thread))

![advance2](../Images/ed4742f796387919b0fe0f40c94f454c.png)

在对象检测的深度学习最新进展系列的第二部分中，我们将总结对象检测的三个方面，提议生成、特征表示学习和学习策略。

## 提案生成

建议生成器生成一组矩形边界框，它们是潜在的对象。

![rpn](../Images/31069f384c15514c95be5272a3f2ffb0.png)

 <svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ev="http://www.w3.org/2001/xml-events" xmlns:v="http://schemas.microsoft.com/visio/2003/SVGExtensions/" viewBox="0 0 580.434 1441.78" xml:space="preserve" color-interpolation-filters="sRGB" style="fill: none; fill-rule: evenodd; font-size: 12px; overflow: visible; stroke-linecap: square; stroke-miterlimit: 3;"><g v:mid="119" v:index="40" v:groupcontext="foregroundPage"><title>adv4-Proposal Generation</title> <g id="shape2-1" v:mid="2" v:groupcontext="shape" transform="translate(18.375,-1202)"><title>工作表.2</title> <desc>Traditional Computer Vision Methods</desc> <text x="21.98" y="1326.88" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Traditional Computer Vision <tspan x="76.25" dy="1.2em" style="font-size: 1em;">Methods</tspan></text></g> <g id="shape3-5" v:mid="3" v:groupcontext="shape" transform="translate(222.288,-1202)"><title>工作表.3</title> <desc>i) computing the ’objectness score’ of a candidate box; ii) m...</desc> <text x="4" y="1251.17" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">i) computing the ’objectness score’of a candidate box; ii) <tspan x="4" dy="1.208em" style="font-size: 1em;">merging super</tspan>-pixels from original images; iii) generating <tspan x="4" dy="1.223em" style="font-size: 1em;">multiple foreground and background segments;</tspan><tspan x="4" dy="1.208em" style="font-size: 1em;">primary advantage of these traditional computer vision</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">methods is that they are very simple and can generate</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">proposals with high recall.</tspan><tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">Mainly based on low-level visual cues such as color or</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">edges. They cannot be jointly optimized with the whole</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">detection pipeline. Thus they are unable to exploit the</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">power of large scale datasets to improve representation</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">learning.</tspan></text></g> <g id="shape4-19" v:mid="4" v:groupcontext="shape" transform="translate(18.375,-540.554)"><title>工作表.4</title> <desc>Anchor-based Methods</desc> <text x="16.47" y="1098.54" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Anchor-<tspan x="22.18" dy="1.2em" style="font-size: 1em;">based</tspan> <tspan x="13.52" dy="1.2em" style="font-size: 1em;">Methods</tspan></text></g> <g id="shape5-24" v:mid="5" v:groupcontext="shape" transform="translate(96.6005,-1073.48)"><title>工作表.5</title> <desc>Region Proposal Network (RPN)</desc> <text x="16.78" y="1373.33" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Region Proposal <tspan x="20.31" dy="1.2em" style="font-size: 1em;">Network (RPN)</tspan></text></g> <g id="shape6-28" v:mid="6" v:groupcontext="shape" transform="translate(96.6005,-1013.23)"><title>工作表.6</title> <desc>SSD - multi-scale anchors</desc> <text x="15.58" y="1407.46" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">SSD - multi-scale <tspan x="40.2" dy="1.2em" style="font-size: 1em;">anchors</tspan></text></g> <g id="shape7-32" v:mid="7" v:groupcontext="shape" transform="translate(222.288,-1073.48)"><title>工作表.7</title> <desc>256−dimensional feature vector was extracted from each anchor...</desc> <text x="4" y="1322.93" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">256−dimensional feature vector was <tspan x="4" dy="1.2em" style="font-size: 1em;">extracted from each anchor and was fed</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">into two sibling branches</tspan> - classification <tspan x="4" dy="1.2em" style="font-size: 1em;">layer and regression layer. First evaluated</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">whether the anchor proposal was</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">foreground or background and performed</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">the categorical classification in the next</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">stage.</tspan></text></g> <g id="shape8-42" v:mid="8" v:groupcontext="shape" transform="translate(222.288,-1013.44)"><title>工作表.8</title> <desc>Assigned categorical probabilities to each anchor proposal.</desc> <text x="4" y="1407.56" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Assigned categorical probabilities to each <tspan x="4" dy="1.2em" style="font-size: 1em;">anchor proposal.</tspan></text></g> <g id="shape10-46" v:mid="10" v:groupcontext="shape" transform="translate(96.6005,-916.368)"><title>工作表.10</title> <desc>Single Shot Scaleinvariant Face Detector (S3FD)</desc> <text x="31.31" y="1379.74" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Single Shot <tspan x="8.27" dy="1.2em" style="font-size: 1em;">Scaleinvariant Face</tspan> <tspan x="17.54" dy="1.2em" style="font-size: 1em;">Detector (S3FD)</tspan></text></g> <g id="shape11-51" v:mid="11" v:groupcontext="shape" transform="translate(222.288,-916.639)"><title>工作表.11</title> <desc>Based on SSD with carefully designed anchors to match the obj...</desc> <text x="4" y="1371.47" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Based on SSD with carefully designed anchors to match <tspan x="4" dy="1.2em" style="font-size: 1em;">the objects. According to the effective receptive field of</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">different feature maps, different anchor priors were</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">designed.</tspan></text></g> <g id="shape12-57" v:mid="12" v:groupcontext="shape" transform="translate(96.6005,-782.744)"><title>工作表.12</title> <desc>Dimension-Decomposition Region Proposal Network (DeRPN)</desc> <text x="30.18" y="1353.47" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Dimension-<tspan x="19.64" dy="1.2em" style="font-size: 1em;">Decomposition</tspan> <tspan x="16.75" dy="1.2em" style="font-size: 1em;">Region Proposal</tspan> <tspan x="12.49" dy="1.2em" style="font-size: 1em;">Network (DeRPN)</tspan></text></g> <g id="shape13-63" v:mid="13" v:groupcontext="shape" transform="translate(222.288,-782.778)"><title>工作表.13</title> <desc>Used an anchor string mechanism to independently match object...</desc> <text x="4" y="1353.49" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Used an anchor string mechanism to independently <tspan x="4" dy="1.2em" style="font-size: 1em;">match objects width and height. This helped match</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">objects with large scale variance and reduced the</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">searching space.</tspan></text></g> <g id="shape15-69" v:mid="15" v:groupcontext="shape" transform="translate(96.6004,-683.883)"><title>工作表.15</title> <desc>Single-Shot Refinement Neural Network (RefineDet)</desc> <text x="32.33" y="1371.34" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Single-Shot <tspan x="8.76" dy="1.2em" style="font-size: 1em;">Refinement Neural</tspan> <tspan x="38.04" dy="1.2em" style="font-size: 1em;">Network</tspan> <tspan x="30.14" dy="1.2em" style="font-size: 1em;">(RefineDet)</tspan></text></g> <g id="shape16-75" v:mid="16" v:groupcontext="shape" transform="translate(222.288,-684.154)"><title>工作表.16</title> <desc>Refined the manually defined anchors in two steps. Significan...</desc> <text x="4" y="1379.87" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Refined the manually defined anchors in two steps. <tspan x="4" dy="1.2em" style="font-size: 1em;">Significantly improved the anchor quality and final</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">prediction accuracy in a data</tspan>-driven manner.</text></g> <g id="shape17-80" v:mid="17" v:groupcontext="shape" transform="translate(96.6004,-638.533)"><title>工作表.17</title> <desc>Cascade R-CNN</desc> <text x="19.11" y="1423.26" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Cascade R-CNN</text></g> <g id="shape18-83" v:mid="18" v:groupcontext="shape" transform="translate(222.288,-638.707)"><title>工作表.18</title> <desc>Refining proposals in a cascaded way.</desc> <text x="4" y="1423.26" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Refining proposals in a cascaded way.</text></g> <g id="shape19-86" v:mid="19" v:groupcontext="shape" transform="translate(96.6004,-540.554)"><title>工作表.19</title> <desc>MetaAnchor</desc> <text x="27.04" y="1396.09" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">MetaAnchor</text></g> <g id="shape20-89" v:mid="20" v:groupcontext="shape" transform="translate(222.288,-540.554)"><title>工作表.20</title> <desc>Improvement compared to other manually defined methods but th...</desc> <text x="4" y="1379.29" style="fill: #198742; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">The improvement compared to other manually defined <tspan x="4" dy="1.2em" style="font-size: 1em;">methods</tspan><tspan style="fill: #ff0000; font-size: 1em;">but the customized anchors were still designed</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">manually.</tspan></text></g> <g id="shape21-96" v:mid="21" v:groupcontext="shape" transform="translate(18.3757,-132.689)"><title>工作表.21</title> <desc>Keypoints-based Methods</desc> <text x="8.95" y="1225.25" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Keypoints-<tspan x="22.18" dy="1.2em" style="font-size: 1em;">based</tspan> <tspan x="13.52" dy="1.2em" style="font-size: 1em;">Methods</tspan></text></g> <g id="shape22-101" v:mid="22" v:groupcontext="shape" transform="translate(96.6005,-426.72)"><title>工作表.22</title> <desc>Denet</desc> <text x="45.41" y="1389.07" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Denet</text></g> <g id="shape23-104" v:mid="23" v:groupcontext="shape" transform="translate(222.288,-426.72)"><title>工作表.23</title> <desc>Modeled the distribution of being one of the 4 corner types o...</desc> <text x="4" y="1363.87" style="fill: #00882b; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Modeled the distribution of being one of the 4 corner <tspan x="4" dy="1.2em" style="font-size: 1em;">types of objects. This corner</tspan>-based algorithm eliminated <tspan x="4" dy="1.2em" style="font-size: 1em;">the design of anchors and became a more effective</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">method to produce high-quality proposals.</tspan></text></g> <g id="shape24-110" v:mid="24" v:groupcontext="shape" transform="translate(96.6005,-312.886)"><title>工作表.24</title> <desc>CornerNet</desc> <text x="32.89" y="1389.07" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">CornerNet</text></g> <g id="shape25-113" v:mid="25" v:groupcontext="shape" transform="translate(222.288,-312.886)"><title>工作表.25</title> <desc>Modeled information of top-left and bottom-right corners. Nov...</desc> <text x="4" y="1355.47" style="fill: #00882b; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Modeled information of top-left and bottom-right <tspan x="4" dy="1.2em" style="font-size: 1em;">corners. Novel feature embedding methods and corner</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">pooling layer to correctly match keypoints belonging to</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">the same objects, obtaining state</tspan>-of-the-art results on <tspan x="4" dy="1.2em" style="font-size: 1em;">public benchmarks.</tspan></text></g> <g id="shape28-120" v:mid="28" v:groupcontext="shape" transform="translate(96.6005,-241.788)"><title>工作表.28</title> <desc>feature-selection-anchor-free (FSAF)</desc> <text x="12.29" y="1402.04" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">feature-selection-<tspan x="10.07" dy="1.2em" style="font-size: 1em;">anchor</tspan>-free (FSAF)</text></g> <g id="shape29-124" v:mid="29" v:groupcontext="shape" transform="translate(96.6005,-132.691)"><title>工作表.29</title> <desc>CenterNet</desc> <text x="34.78" y="1391.44" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">CenterNet</text></g> <g id="shape30-127" v:mid="30" v:groupcontext="shape" transform="translate(222.288,-132.691)"><title>工作表.30</title> <desc>Combined the idea of center-based methods and corner-based me...</desc> <text x="4" y="1366.24" style="fill: #00882b; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Combined the idea of center-based methods and corner-<tspan x="4" dy="1.2em" style="font-size: 1em;">based methods. First predicted bounding boxes by pairs</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">of corners, and then predicted center probabilities of the</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">initial prediction to reject easy negatives.</tspan></text></g> <g id="shape31-133" v:mid="31" v:groupcontext="shape" transform="translate(222.288,-241.788)"><title>工作表.31</title> <desc>An online feature selection block is applied to train multile...</desc> <text x="4" y="1393.64" style="fill: #00882b; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">An online feature selection block is applied to train <tspan x="4" dy="1.2em" style="font-size: 1em;">multilevel center</tspan>-based branches attached in each level of <tspan x="4" dy="1.2em" style="font-size: 1em;">the feature pyramid.</tspan></text></g> <g id="shape32-138" v:mid="32" v:groupcontext="shape" transform="translate(96.6005,-18.375)"><title>工作表.32</title> <desc>AZnet</desc> <text x="47.45" y="1388.83" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">AZnet</text></g> <g id="shape33-141" v:mid="33" v:groupcontext="shape" transform="translate(222.288,-18.375)"><title>工作表.33</title> <desc>Predicted two values: zoom indicator and adjacency scores. Zo...</desc> <text x="4" y="1346.83" style="fill: #00882b; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Predicted two values: zoom indicator and adjacency <tspan x="4" dy="1.2em" style="font-size: 1em;">scores. Zoom indicator determined whether to further</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">divide this region which may contain smaller objects and</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">adjacency scores denoted its objectness. Better at</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">matching sparse and small objects compared to RPN</tspan>’s <tspan x="4" dy="1.2em" style="font-size: 1em;">anchor</tspan>-object matching approach.</text></g> <g id="shape77-149" v:mid="77" v:groupcontext="shape" transform="translate(482.847,-1015.26)"><title>工作表.77</title> <desc>The anchor priors are manually designed with multiple scales ...</desc> <text x="4" y="1268.62" style="fill: #ff0000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">The anchor <tspan x="4" dy="1.2em" style="font-size: 1em;">priors are</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">manually</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">designed</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">with</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">multiple</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">scales and</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">aspect</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">ratios in a</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">heuristic</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">manner.</tspan></text></g> <g id="shape103-162" v:mid="103" v:groupcontext="shape" transform="translate(18.3757,-18.375)"><title>工作表.103</title> <desc>Other Methods</desc> <text x="22.53" y="1380.43" style="fill: #000000; font-family: Calibri; font-size: 1.16666em;" v:langid="1033">Other <tspan x="13.52" dy="1.2em" style="font-size: 1em;">Methods</tspan></text></g></g></svg>

## 特征表征学习

三类:多尺度特征学习、上下文推理、可变形特征学习。

![multi-scale](../Images/05745ff0bbb656a798acaba37c893a17.png)

 <svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ev="http://www.w3.org/2001/xml-events" xmlns:v="http://schemas.microsoft.com/visio/2003/SVGExtensions/" viewBox="0 0 467.616 830.684" xml:space="preserve" color-interpolation-filters="sRGB" style="fill: none; fill-rule: evenodd; font-size: 12px; overflow: visible; stroke-linecap: square; stroke-miterlimit: 3;"><g v:mid="122" v:index="41" v:groupcontext="foregroundPage"><title>adv5</title> <g id="shape1-1" v:mid="1" v:groupcontext="shape" transform="translate(18.375,-519.98)"><title>工作表.1</title> <desc>Multi-scale feature learning</desc> <text x="7.36" y="673.72" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Multi-scale <tspan x="16.43" dy="1.2em" style="font-size: 1em;">feature</tspan> <tspan x="14.52" dy="1.2em" style="font-size: 1em;">learning</tspan></text></g> <g id="shape2-6" v:mid="2" v:groupcontext="shape" transform="translate(18.375,-76.1936)"><title>工作表.2</title> <desc>Contextual reasoning</desc> <text x="7.84" y="782.51" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Contextual <tspan x="10.39" dy="1.2em" style="font-size: 1em;">reasoning</tspan></text></g> <g id="shape3-10" v:mid="3" v:groupcontext="shape" transform="translate(18.375,-18.376)"><title>工作表.3</title> <desc>deformable feature learning</desc> <text x="5.95" y="790.97" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">deformable <tspan x="16.43" dy="1.2em" style="font-size: 1em;">feature</tspan> <tspan x="14.52" dy="1.2em" style="font-size: 1em;">learning</tspan></text></g> <g id="shape4-15" v:mid="4" v:groupcontext="shape" transform="translate(87.093,-739.121)"><title>工作表.4</title> <desc>Image Pyramid</desc> <text x="23.99" y="790.49" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Image <tspan x="18.87" dy="1.2em" style="font-size: 1em;">Pyramid</tspan></text></g> <g id="shape5-19" v:mid="5" v:groupcontext="shape" transform="translate(165.042,-739.121)"><title>工作表.5</title> <desc>Resize input images into a number of different scales (Image ...</desc> <text x="4" y="779.09" style="fill: #000000; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Resize input images into a number of different scales (Image <tspan x="4" dy="1.2em" style="font-size: 1em;">Pyramid) and to train multiple detectors. Each of which is</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">responsible for a certain range of scales. Examples: Scale</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">Normalization for Image Pyramids (SNIP).</tspan></text></g> <g id="shape6-25" v:mid="6" v:groupcontext="shape" transform="translate(87.093,-665.775)"><title>工作表.6</title> <desc>Integrated Features</desc> <text x="13.38" y="790.49" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Integrated <tspan x="17.77" dy="1.2em" style="font-size: 1em;">Features</tspan></text></g> <g id="shape7-29" v:mid="7" v:groupcontext="shape" transform="translate(165.042,-665.775)"><title>工作表.7</title> <desc>Construct a single feature map by combining features in multi...</desc> <text x="4" y="779.09" style="fill: #000000; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Construct a single feature map by combining features in multiple <tspan x="4" dy="1.2em" style="font-size: 1em;">layers and making final predictions based on the newly constructed</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">map. Examples: Inside</tspan>-Outside Network (ION), HyperNet, Multi-<tspan x="4" dy="1.2em" style="font-size: 1em;">scale Location</tspan>-aware Kernel Representation (MLKP).</text></g> <g id="shape8-35" v:mid="8" v:groupcontext="shape" transform="translate(87.093,-593.24)"><title>工作表.8</title> <desc>Prediction Pyramid</desc> <text x="14.03" y="790.49" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Prediction <tspan x="18.87" dy="1.2em" style="font-size: 1em;">Pyramid</tspan></text></g> <g id="shape9-39" v:mid="9" v:groupcontext="shape" transform="translate(165.042,-593.24)"><title>工作表.9</title> <desc>Predictions were made from multiple layers, where each layer ...</desc> <text x="4" y="785.09" style="fill: #000000; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Predictions were made from multiple layers, where each layer was <tspan x="4" dy="1.2em" style="font-size: 1em;">responsible for a certain scale of objects. Examples: SSD, Receptive</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">Field Block Net (RFBNet).</tspan></text></g> <g id="shape10-44" v:mid="10" v:groupcontext="shape" transform="translate(87.093,-520.052)"><title>工作表.10</title> <desc>Feature Pyramid</desc> <text x="20.12" y="790.49" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Feature <tspan x="18.87" dy="1.2em" style="font-size: 1em;">Pyramid</tspan></text></g> <g id="shape11-48" v:mid="11" v:groupcontext="shape" transform="translate(165.042,-520.052)"><title>工作表.11</title> <desc>Combine the advantage of Integrated Features and Prediction P...</desc> <text x="4" y="791.09" style="fill: #198742; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Combine the advantage of Integrated Features and Prediction <tspan x="4" dy="1.2em" style="font-size: 1em;">Pyramid.</tspan><tspan style="fill: #000000; font-size: 1em;">Example: Feature Pyramid Network(FPN).</tspan></text></g> <g id="shape12-54" v:mid="12" v:groupcontext="shape" transform="translate(18.375,-165.331)"><title>工作表.12</title> <desc>Region Feature Encoding</desc> <text x="17.6" y="642.56" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Region <tspan x="15.5" dy="1.2em" style="font-size: 1em;">Feature</tspan> <tspan x="12.07" dy="1.2em" style="font-size: 1em;">Encoding</tspan></text></g> <g id="shape13-59" v:mid="13" v:groupcontext="shape" transform="translate(87.093,-494.393)"><title>工作表.13</title> <desc>ROI Pooling</desc> <text x="12.07" y="821.51" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">ROI Pooling</text></g> <g id="shape14-62" v:mid="14" v:groupcontext="shape" transform="translate(165.042,-494.501)"><title>工作表.14</title> <desc>Extracted features from the down-sampled feature map and as a...</desc> <text x="4" y="814.91" style="fill: #ff0000; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Extracted features from the down-sampled feature map and as a <tspan x="4" dy="1.2em" style="font-size: 1em;">result struggled to handle small objects.</tspan></text></g> <g id="shape15-66" v:mid="15" v:groupcontext="shape" transform="translate(87.093,-444.743)"><title>工作表.15</title> <desc>ROI Warping</desc> <text x="9.42" y="809.33" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">ROI Warping</text></g> <g id="shape16-69" v:mid="16" v:groupcontext="shape" transform="translate(165.042,-444.743)"><title>工作表.16</title> <desc>Encoded region features via bilinear interpolation. Due to th...</desc> <text x="4" y="790.73" style="fill: #000000; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">The encoded region features via bilinear interpolation. <tspan style="fill: #ff0000; font-size: 1em;">Due to the</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">downsampling operation in DCNN, there can be a misalignment of</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">the object position in the original image and the downsampled</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em;">feature maps.</tspan></text></g> <g id="shape17-76" v:mid="17" v:groupcontext="shape" transform="translate(87.0933,-403.266)"><title>工作表.17</title> <desc>ROI Align</desc> <text x="16.67" y="813.55" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">ROI Align</text></g> <g id="shape18-79" v:mid="18" v:groupcontext="shape" transform="translate(165.042,-403.266)"><title>工作表.18</title> <desc>Addressed the quantization issue by bilinear interpolation at...</desc> <text x="4" y="806.95" style="fill: #198742; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Addressed the quantization issue by bilinear interpolation at <tspan x="4" dy="1.2em" style="font-size: 1em;">fractionally sampled positions within each grid.</tspan></text></g> <g id="shape19-83" v:mid="19" v:groupcontext="shape" transform="translate(87.0937,-344.892)"><title>工作表.19</title> <desc>Precise ROI Pooing (PrROI Pooling)</desc> <text x="11.45" y="790.7" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Precise ROI <tspan x="5.08" dy="1.2em" style="font-size: 1em;">Pooing (PrROI</tspan> <tspan x="19" dy="1.2em" style="font-size: 1em;">Pooling)</tspan></text></g> <g id="shape20-88" v:mid="20" v:groupcontext="shape" transform="translate(165.043,-344.892)"><title>工作表.20</title> <desc>Avoided any quantization of coordinates and had a continuous ...</desc> <text x="4" y="798.5" style="fill: #198742; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Avoided any quantization of coordinates and had a continuous <tspan x="4" dy="1.2em" style="font-size: 1em;">gradient on bounding box coordinates.</tspan></text></g> <g id="shape21-92" v:mid="21" v:groupcontext="shape" transform="translate(87.093,-273.492)"><title>工作表.21</title> <desc>Position Sensitive ROI Pooing (PSROI Pooling)</desc> <text x="19.28" y="776.98" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Position <tspan x="7.18" dy="1.2em" style="font-size: 1em;">Sensitive ROI</tspan> <tspan x="4.42" dy="1.2em" style="font-size: 1em;">Pooing (PSROI</tspan> <tspan x="19" dy="1.2em" style="font-size: 1em;">Pooling)</tspan></text></g> <g id="shape22-98" v:mid="22" v:groupcontext="shape" transform="translate(165.043,-273.492)"><title>工作表.22</title> <desc>Enhance spatial information of the downsampled region features</desc> <text x="4" y="797.98" style="fill: #198742; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Enhance spatial information of the downsampled region features.</text></g> <g id="shape23-101" v:mid="23" v:groupcontext="shape" transform="translate(87.0932,-218.331)"><title>工作表.23</title> <desc>CoupleNet</desc> <text x="13.08" y="806.7" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">CoupleNet</text></g> <g id="shape24-104" v:mid="24" v:groupcontext="shape" transform="translate(165.043,-218.331)"><title>工作表.24</title> <desc>Combining outputs generated from both ROI Pooling layer and P...</desc> <text x="4" y="788.1" style="fill: #198742; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Combining outputs generated from both ROI Pooling layer and <tspan x="4" dy="1.2em" style="font-size: 1em;">PSROI Pooling layer. ROI Pooling layer extracted global region</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">information but struggled for objects with high occlusion while</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">PSROI Pooling layer focused more on local information.</tspan></text></g> <g id="shape25-110" v:mid="25" v:groupcontext="shape" transform="translate(87.0932,-165.331)"><title>工作表.25</title> <desc>Deformable ROI Pooling</desc> <text x="11.39" y="800.58" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Deformable <tspan x="10.72" dy="1.2em" style="font-size: 1em;">ROI Pooling</tspan></text></g> <g id="shape26-114" v:mid="26" v:groupcontext="shape" transform="translate(165.043,-165.331)"><title>工作表.26</title> <desc>Can automatically model the image content without being const...</desc> <text x="4" y="801.18" style="fill: #198742; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Can automatically model the image content without being <tspan x="4" dy="1.2em" style="font-size: 1em;">constrained by fixed receptive fields.</tspan></text></g> <g id="shape27-118" v:mid="27" v:groupcontext="shape" transform="translate(87.0932,-76.1936)"><title>工作表.27</title> <desc>Learning the relationship between objects with their surround...</desc> <text x="4" y="771.12" style="fill: #459b5c; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Learning the relationship between objects with their surrounding context can improve the <tspan x="4" dy="1.2em" style="font-size: 1em;">detector</tspan>’s ability to understand the scenario.<tspan style="fill: #000000; font-size: 1em;">Two aspects: global context and region</tspan> <tspan x="4" dy="1.2em" style="fill: #000000; font-size: 1em;">context.</tspan> <tspan style="fill: #000000; font-size: 1em;">Examples: Spatial Memory Network (SMN), Structure Inference Net (SIN),</tspan> <tspan x="4" dy="1.2em" style="fill: #000000; font-size: 1em;">Gated Bi</tspan><tspan style="fill: #000000; font-size: 1em;">-</tspan><tspan style="fill: #000000; font-size: 1em;">Directional CNN (GBDNet).</tspan></text></g> <g id="shape28-129" v:mid="28" v:groupcontext="shape" transform="translate(87.0932,-18.375)"><title>工作表.28</title> <desc>Robust to nonrigid deformation of objects. Examples: DeepIDNe...</desc> <text x="4" y="792.77" style="fill: #459b5c; font-family: Calibri; font-size: 0.833336em;" v:langid="1033">Robust to nonrigid deformation of objects.<tspan style="fill: #000000; font-size: 1em;">Examples: DeepIDNet developed a</tspan> <tspan x="4" dy="1.2em" style="fill: #000000; font-size: 1em;">deformable</tspan><tspan style="fill: #000000; font-size: 1em;">-</tspan><tspan style="fill: #000000; font-size: 1em;">aware pooling layer to encode the deformation information across</tspan> <tspan x="4" dy="1.2em" style="fill: #000000; font-size: 1em;">different object categories.</tspan></text></g></g></svg>

## 学习策略

解决不平衡采样、定位、加速等问题。

 <svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ev="http://www.w3.org/2001/xml-events" xmlns:v="http://schemas.microsoft.com/visio/2003/SVGExtensions/" viewBox="0 0 461.946 872.972" xml:space="preserve" color-interpolation-filters="sRGB" style="fill: none; fill-rule: evenodd; font-size: 12px; overflow: visible; stroke-linecap: square; stroke-miterlimit: 3;"><g v:mid="123" v:index="42" v:groupcontext="foregroundPage"><title>adv6</title> <g id="shape1-1" v:mid="1" v:groupcontext="shape" transform="translate(18.375,-221.56)"><title>工作表.1</title> <desc>Training Stage</desc> <text x="10.18" y="552.85" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Training <tspan x="16.51" dy="1.2em" style="font-size: 1em;">Stage</tspan></text></g> <g id="shape2-5" v:mid="2" v:groupcontext="shape" transform="translate(78.3197,-759.999)"><title>工作表.2</title> <desc>Data Augmentation</desc> <text x="30.73" y="822.07" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Data <tspan x="7.21" dy="1.2em" style="font-size: 1em;">Augmentation</tspan></text></g> <g id="shape3-9" v:mid="3" v:groupcontext="shape" transform="translate(162.703,-759.999)"><title>工作表.3</title> <desc>Horizontal flips of training images is used in training Faste...</desc> <text x="4" y="800.47" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Horizontal flips of training images are used in training <tspan x="4" dy="1.2em" style="font-size: 1em;">Faster R</tspan>-CNN detector. <tspan x="4" dy="1.2em" style="font-size: 1em;">A more intensive data augmentation strategy is used in</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">one</tspan>-stage detectors including rotation, random crops, <tspan x="4" dy="1.2em" style="font-size: 1em;">expanding and color jittering.</tspan></text></g> <g id="shape4-16" v:mid="4" v:groupcontext="shape" transform="translate(78.3197,-607.611)"><title>工作表.4</title> <desc>Imbalance Sampling</desc> <text x="18.27" y="793.18" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Imbalance <tspan x="19.87" dy="1.2em" style="font-size: 1em;">Sampling</tspan></text></g> <g id="shape5-20" v:mid="5" v:groupcontext="shape" transform="translate(162.703,-607.611)"><title>工作表.5</title> <desc>Hard negative sampling, negative proposals with higher classi...</desc> <text x="4" y="749.98" style="fill: #000000; font-family: Calibri; font-size: 1.00001em; font-weight: bold;" v:langid="1033">Hard negative sampling<tspan style="font-size: 1em; font-weight: normal;">, negative proposals with</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">higher classification loss were selected for training.</tspan><tspan x="4" dy="1.2em" style="font-size: 1em;">Focal loss</tspan><tspan style="font-size: 1em; font-weight: normal;">. The gradient signals of easy samples got</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">suppressed which led the training process to focus</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">more on hard proposals.</tspan><tspan x="4" dy="1.2em" style="font-size: 1em;">Gradient harmonizing mechanism (GHM)</tspan><tspan style="font-size: 1em; font-weight: normal;">, not only</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">suppressed easy proposals but also avoided the negative</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">impact of outliers.</tspan></text></g> <g id="shape6-33" v:mid="6" v:groupcontext="shape" transform="translate(78.3197,-530.401)"><title>工作表.6</title> <desc>Localization Refinement</desc> <text x="13.38" y="830.77" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Localization <tspan x="13.64" dy="1.2em" style="font-size: 1em;">Refinement</tspan></text></g> <g id="shape7-37" v:mid="7" v:groupcontext="shape" transform="translate(162.703,-530.401)"><title>工作表.7</title> <desc>Examples: LocNet, MultiPath Network, FitnessNMS Grid R-CNN re...</desc> <text x="4" y="816.37" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Examples: LocNet, MultiPath Network, FitnessNMS<tspan x="4" dy="1.2em" style="font-size: 1em;">Grid R</tspan>-CNN replaced linear bounding box regressor <tspan x="4" dy="1.2em" style="font-size: 1em;">with the principle of locating corner keypoints corner</tspan>-<tspan x="4" dy="1.2em" style="font-size: 1em;">based mechanism.</tspan></text></g> <g id="shape8-43" v:mid="8" v:groupcontext="shape" transform="translate(78.3197,-434.904)"><title>工作表.8</title> <desc>Cascade Learning</desc> <text x="22.21" y="821.55" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Cascade <tspan x="21.19" dy="1.2em" style="font-size: 1em;">Learning</tspan></text></g> <g id="shape9-47" v:mid="9" v:groupcontext="shape" transform="translate(162.703,-434.904)"><title>工作表.9</title> <desc>Coarse-to-fine learning strategy which collects information f...</desc> <text x="4" y="799.95" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Coarse-to-fine learning strategy which collects <tspan x="4" dy="1.2em" style="font-size: 1em;">information from the output of the given classifiers to</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">build stronger classifiers in a cascaded manner.</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">RefineDet and Cascade R</tspan>-CNN utilized cascade learning <tspan x="4" dy="1.2em" style="font-size: 1em;">methods in refining object locations.</tspan></text></g> <g id="shape10-54" v:mid="10" v:groupcontext="shape" transform="translate(78.3197,-221.56)"><title>工作表.10</title> <desc>Others</desc> <text x="25.62" y="769.9" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Others</text></g> <g id="shape11-57" v:mid="11" v:groupcontext="shape" transform="translate(162.703,-221.56)"><title>工作表.11</title> <desc>Adversarial learning, Perceptual GAN for small object detecti...</desc> <text x="4" y="676.48" style="fill: #000000; font-family: Calibri; font-size: 1.00001em; font-weight: bold;" v:langid="1033">Adversarial learning<tspan style="font-size: 1em; font-weight: normal;">, Perceptual GAN for small object</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">detection. Learned high</tspan><tspan style="font-size: 1em; font-weight: normal;">-</tspan><tspan style="font-size: 1em; font-weight: normal;">resolution feature</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">representations of small objects via an adversarial</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">scheme.</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">Training from Scratch</tspan><tspan style="font-size: 1em; font-weight: normal;">. For two reasons. The bias of</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">loss functions and data distribution between</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">classification and detection can have an adversarial</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">impact on the performance.</tspan> <tspan style="font-size: 1em; font-weight: normal;">Transferring a classification</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">model for detection in a new domain can lead to more</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">challenges. Examples: DSOD (Deeply Supervised Object</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">Detectors), gated recurrent feature pyramid.</tspan><tspan x="4" dy="1.2em" style="font-size: 1em;">Knowledge Distillation</tspan><tspan style="font-size: 1em; font-weight: normal;">. Distills the knowledge in an</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">ensemble of models into a single model via teacher</tspan><tspan style="font-size: 1em; font-weight: normal;">-</tspan><tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">student training scheme.</tspan></text></g> <g id="shape12-80" v:mid="12" v:groupcontext="shape" transform="translate(18.375,-18.375)"><title>工作表.12</title> <desc>Testing Stage</desc> <text x="12.34" y="767.78" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Testing <tspan x="16.51" dy="1.2em" style="font-size: 1em;">Stage</tspan></text></g> <g id="shape13-84" v:mid="13" v:groupcontext="shape" transform="translate(78.3197,-103.714)"><title>工作表.13</title> <desc>Duplicate Removal</desc> <text x="19.02" y="810.45" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Duplicate <tspan x="21.01" dy="1.2em" style="font-size: 1em;">Removal</tspan></text></g> <g id="shape14-88" v:mid="14" v:groupcontext="shape" transform="translate(162.703,-103.714)"><title>工作表.14</title> <desc>Non maximum suppression(NMS), predefined threshold will resul...</desc> <text x="4" y="781.65" style="fill: #000000; font-family: Calibri; font-size: 1.00001em; font-weight: bold;" v:langid="1033">Non maximum suppression(NMS)<tspan style="font-size: 1em; font-weight: normal;">, the </tspan><tspan style="fill: #ff0000; font-size: 1em; font-weight: normal;">predefined</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em; font-weight: normal;">threshold will result in a missing prediction, and this</tspan> <tspan x="4" dy="1.2em" style="fill: #ff0000; font-size: 1em; font-weight: normal;">scenario is very common in clustered object detection.</tspan><tspan x="4" dy="1.2em" style="font-size: 1em;">Soft</tspan>-NMS<tspan style="font-size: 1em; font-weight: normal;">, decayed the confidence score of B as a</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em; font-weight: normal;">continuous function F.</tspan> <tspan style="fill: #198742; font-size: 1em; font-weight: normal;">Avoided eliminating prediction</tspan> <tspan x="4" dy="1.2em" style="fill: #198742; font-size: 1em; font-weight: normal;">of clustered objects</tspan><tspan style="font-size: 1em; font-weight: normal;">.</tspan></text></g> <g id="shape15-101" v:mid="15" v:groupcontext="shape" transform="translate(78.3197,-18.3751)"><title>工作表.15</title> <desc>Model Acceleration</desc> <text x="26.37" y="826.7" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Model <tspan x="11.61" dy="1.2em" style="font-size: 1em;">Acceleration</tspan></text></g> <g id="shape16-105" v:mid="16" v:groupcontext="shape" transform="translate(162.702,-18.3751)"><title>工作表.16</title> <desc>Examples: R-FCN, Light Head R-CNN, MobileNet with depth-wise ...</desc> <text x="4" y="812.3" style="fill: #000000; font-family: Calibri; font-size: 1.00001em;" v:langid="1033">Examples: R-FCN, Light Head R-CNN, MobileNet with <tspan x="4" dy="1.2em" style="font-size: 1em;">depth</tspan>-wise convolution layers. Optimize models off-<tspan x="4" dy="1.2em" style="font-size: 1em;">line, such as model compression and quantization.</tspan> <tspan x="4" dy="1.2em" style="font-size: 1em;">Acceleration toolkit TensorRT.</tspan></text></g></g></svg>

## 结论和进一步的思考

本系列概述了深度学习中用于对象检测的几个关键部分，以及它们如何相互建立。最后，让我们用 FPN 更快的 RCNN 的网络结构来结束这个系列。

![two-stage-network](../Images/66ee42099b431d3a821fed9c168b9fbf.png)

*   标签:
*   [深度学习](/blog/tag/deep-learning/)，
*   [教程](/blog/tag/tutorial/)

[Share on Twitter](https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/recent-advances-in-deep-learning-for-object-detection-part-2/&text=Recent%20Advances%20in%20Deep%20Learning%20for%20Object%20Detection%20-%20Part%202) [Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/recent-advances-in-deep-learning-for-object-detection-part-2/)

*   [←物体检测深度学习的最新进展-第一部分](/blog/recent-advances-in-deep-learning-for-object-detection/)
*   [VS 代码远程开发入门→](/blog/getting-started-with-vscode-remote-development/)